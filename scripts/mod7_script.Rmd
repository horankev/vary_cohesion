---
title: "mod7_script"
output: html_document
date: "2025-05-02"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
```


## Libraries

```{r, echo=FALSE}
library(dplyr, quietly = TRUE)
library(ggplot2, quietly = TRUE)
library(stringr, quietly = TRUE)
library(tidyr, quietly = TRUE)
library(tibble, quietly = TRUE)
library(sf, quietly = TRUE)
library(here, quietly = TRUE)
library(janitor, quietly = TRUE)
library(sfislands, quietly = TRUE)
library(sfdep, quietly = TRUE)
library(rmapshaper, quietly = TRUE)
library(janitor, quietly = TRUE)

library(brms, quietly = TRUE)
library(rstan, quietly = TRUE)
library(geostan, quietly = TRUE) # for prep_icar_data() function
library(bridgesampling, quietly = TRUE)

set.seed(123)
```

## Data preparation

### Voting data 2017-2024

```{r, echo=FALSE}
custom_palette <- c("lab"="#E4003B",
                    "con"="#0087DC",
                    "ld"="#FAA61A",
                    # "ruk"="#12B6CF",
                    "ruk"="darkblue", # this gives better separation than suggested colour
                    "brx"="darkblue", 
                    "ukip"="darkblue",
                    "ind"="#8C0064",
                    "green"="#4BA663",
                    "pc"="#005B54",
                    "spk"="#DCDCDC",
                    "other"="gray20")

# constituencies in 2017 and 2019
constituencies19 <- st_read(here("data","boundaries","Westminster_Parliamentary_Constituencies_Dec_2019_Boundaries_UK_BFE_2022_5896292250094173431.geojson"), quiet = TRUE) |> 
  select(pcon19cd,pcon19nm,geometry) |> 
  rename(con_name = pcon19nm,
         con_code = pcon19cd) |> 
  ms_simplify() |> 
  filter(str_detect(con_code,"E")) # only England

# projection data to 2024
all_changes <- readxl::read_xlsx(here("data","boundaries","Boundary_changes_data_file.xlsx"), 
                                 sheet = 3, skip = 1)

projection_df <- all_changes |> 
  select(1:4,9,11) |> 
  rename(prop_old_in_new = `Percentage of old constituency in this segment (population) [notes 1 and 2]`)

```


```{r, echo=FALSE}

# 2017 votes
votes17 <- read.csv(here("data","results","HoC-GE2017-results-by-constituency.csv")) |> 
  clean_names() |> 
  left_join(constituencies19 |> select(con_code,geometry),
            by = c("ons_id"="con_code")) |> 
  filter(country_name == "England") |>  # only England
  rename(con_code = ons_id) |> 
  mutate(other = green + all_other_candidates) |> 
  rename(ruk = ukip) |> 
  select(con_code,constituency_name,region_name,majority,valid_votes,con,lab,ld,ruk,other,geometry) |> 
  st_as_sf()

# 2017 votes projected to 2024 constituencies
votes17proj <- votes17 |> 
  select(con_code,majority,valid_votes,con,lab,ld,ruk,other) |> 
  st_drop_geometry() |> 
  pivot_longer("majority":"other") |> 
  left_join(projection_df,
            by = c("con_code"="Current constituency code")) |> 
  mutate(value = prop_old_in_new * value) |> 
  select(name,value,`New constituency name`,`New constituency code`) |> 
  mutate(name = factor(name,
                       levels = c("con","lab","ld","ruk","other","valid_votes","majority"))) |> 
  rename(constituency_name = `New constituency name`, 
         con_code = `New constituency code`) |> 
  group_by(con_code, name) |> 
  summarise(value = sum(value) |> round()) |> 
  pivot_wider(names_from = "name",values_from = "value") |> 
  rowwise() |> 
  mutate(
    first_party17 = colnames(across(con:other))[which.max(c_across(con:other))], 
    second_party17 = colnames(across(con:other))[order(-c_across(con:other))[2]], 
    third_party17 = colnames(across(con:other))[order(-c_across(con:other))[3]]
  ) |> 
  ungroup() |> 
  rename(con17 = con,
         lab17 = lab,
         ld17 = ld,
         ruk17 = ruk,
         other17 = other,
         valid_votes17 = valid_votes,
         majority17 = majority) |> 
  mutate(con17_pct = 100*con17/valid_votes17,
         lab17_pct = 100*lab17/valid_votes17,
         ld17_pct = 100*ld17/valid_votes17,
         ruk17_pct = 100*ruk17/valid_votes17,
         other17_pct = 100*other17/valid_votes17)


# 2019 votes
votes19 <- read.csv(here("data","results","HoC-GE2019-results-by-constituency.csv")) |> 
  clean_names() |> 
  left_join(constituencies19 |> select(con_code,geometry),
            by = c("ons_id"="con_code")) |> 
  filter(country_name == "England") |> # only England
  rename(con_code = ons_id) |> 
  mutate(other = green + all_other_candidates) |> 
  rename(ruk = brx) |> 
  select(con_code,constituency_name,region_name,majority,valid_votes,first_party,second_party,con,lab,ld,ruk,other,geometry) |> 
  st_as_sf()

# 2019 votes projected to 2024 constituencies
votes19proj <- votes19 |> 
  select(con_code,majority,valid_votes,con,lab,ld,ruk,other) |> 
  st_drop_geometry() |> 
  pivot_longer("majority":"other") |> 
  left_join(projection_df,
            by = c("con_code"="Current constituency code")) |> 
  mutate(value = prop_old_in_new * value) |> 
  select(name,value,`New constituency name`,`New constituency code`) |> 
  mutate(name = factor(name,
                       levels = c("con","lab","ld","ruk","other","valid_votes","majority"))) |> 
  rename(constituency_name = `New constituency name`, 
         con_code = `New constituency code`) |> 
  group_by(con_code, name) |> 
  summarise(value = sum(value) |> round()) |> 
  pivot_wider(names_from = "name",values_from = "value") |> 
  rowwise() |> 
  mutate(
    first_party19 = colnames(across(con:other))[which.max(c_across(con:other))], 
    second_party19 = colnames(across(con:other))[order(-c_across(con:other))[2]], 
    third_party19 = colnames(across(con:other))[order(-c_across(con:other))[3]]
  ) |> 
  ungroup() |> 
  rename(con19 = con,
         lab19 = lab,
         ld19 = ld,
         ruk19 = ruk,
         other19 = other,
         valid_votes19 = valid_votes,
         majority19 = majority) |> 
  mutate(con19_pct = 100*con19/valid_votes19,
         lab19_pct = 100*lab19/valid_votes19,
         ld19_pct = 100*ld19/valid_votes19,
         ruk19_pct = 100*ruk19/valid_votes19,
         other19_pct = 100*other19/valid_votes19)


## Boundaries for constituencies and regions 2024
constituencies24 <- st_read(here("data","boundaries","geoConstituencies.json"), quiet = TRUE) |> 
  st_make_valid() |> 
  select(PCON24CD,PCON24NM,name3,regionNM,geometry) |> 
  rename(con_name = PCON24NM,
         con_code = PCON24CD,
         reg_name = regionNM,
         con_abb = name3) |> 
  filter(!reg_name %in% c("Scotland","Wales","Northern Ireland"))

regions <- constituencies24 |> 
  ms_dissolve("reg_name") |> 
  mutate(reg_name = case_when(reg_name == "Greater London" ~ "London",
                              reg_name == "Yorkshire and the Humber" ~ "Yorkshire and The Humber",
                              TRUE ~ reg_name))

hex24 <- st_read(here("data","boundaries","hexConstituencies.json"), quiet = TRUE) |> 
  select(PCON24CD,PCON24NM,name3,regionNM,geometry) |> 
  rename(con_name = PCON24NM,
         con_code = PCON24CD,
         reg_name = regionNM,
         con_abb = name3) |> 
  filter(!reg_name %in% c("Scotland","Northern Ireland","Wales")) # only England

hex_reg24 <- hex24 |> 
  ms_dissolve("reg_name")

# 2024 votes
votes24 <- read.csv(here("data","results","HoC-GE2024-results-by-constituency.csv")) |> 
  clean_names() |> 
  left_join(constituencies24 |> select(con_code,con_abb,geometry),
            by = c("ons_id"="con_code")) |> 
  filter(country_name == "England") |>  # only England
  rename(con_code = ons_id) |> 
  mutate(other = green + all_other_candidates,
         first_party = tolower(first_party),
         second_party = tolower(second_party)) |> 
  select(con_code,constituency_name,region_name,first_party,second_party,con,lab,ld,ruk,other,valid_votes,majority,geometry) |> 
  rename(first_party24 = first_party,
         second_party24= second_party) |> 
  rowwise() |> 
  mutate(
    third_party24 = colnames(across(con:other))[order(-c_across(con:other))[3]]
  ) |> 
  ungroup() |> 
  rename(con24 = con,
         lab24 = lab,
         ld24 = ld,
         ruk24 = ruk,
         other24 = other,
         valid_votes24 = valid_votes,
         majority24 = majority) |>
  mutate(con24_pct = 100*con24/valid_votes24,
         lab24_pct = 100*lab24/valid_votes24,
         ld24_pct = 100*ld24/valid_votes24,
         ruk24_pct = 100*ruk24/valid_votes24,
         other24_pct = 100*other24/valid_votes24) |> 
  st_as_sf()


```

### Census data

```{r, echo=FALSE}
sex_age <- readxl::read_xlsx(here("data","census21","RM121-Sex-By-Age-2021-p19wpc-ONS.xlsx")) |> 
  clean_names() |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies,
           age_23_categories_code,
           age_23_categories) |> 
  summarise(observation = sum(observation))

population <- sex_age |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(pop_tot = sum(observation))

sixteenplus <- sex_age |> 
  filter(age_23_categories_code > 6) |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(sixteenplus_tot = sum(observation))

eighteenplus <- sex_age |> 
  filter(age_23_categories_code > 7) |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(eighteenplus_tot = sum(observation))

over65 <- sex_age |> 
  filter(age_23_categories_code > 18) |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(over65_tot = sum(observation))


education <- readxl::read_xlsx(here("data","census21","TS067-Highest-Level-Of-Qualification-2021-p19wpc-ONS.xlsx")) |> 
  clean_names()
education <- education[education[,3] == "5",] |> 
  rename(degree_tot = observation) |> 
  select(1,2,degree_tot)

disability <- readxl::read_xlsx(here("data","census21","TS038-Disability-2021-p19wpc-ONS.xlsx")) |> 
  clean_names()
# disability <- disability[disability[,3] == 1 | disability[,3] == 2,] |>  # limited a little or a lot
disability <- disability[disability[,3] == 1,] |> # limited a lot
  rename(disability_tot = observation) |> 
  select(1,2,disability_tot) |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(disability_tot = sum(disability_tot))

health <- readxl::read_xlsx(here("data","census21","RM044-General-Health-By-Ns-Sec-2021-p19wpc-ONS.xlsx")) |> 
  clean_names()
health <- health[health[,3] == "3" | health[,3] == "4" | health[,3] == "5",] |> 
  rename(notgoodhealth_tot = observation) |> 
  select(1,2,notgoodhealth_tot) |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(notgoodhealth_tot = sum(notgoodhealth_tot))

white <- readxl::read_xlsx(here("data","census21","RM087-National-Identity-By-Ethnic-Group-2021-p19wpc-ONS.xlsx")) |> 
  clean_names()
white <- white |> 
  filter(str_detect(ethnic_group_8_categories, "White")) |> 
  rename(white_tot = observation) |> 
  select(1,2,white_tot) |> 
  group_by(post_2019_westminster_parliamentary_constituencies_code,
           post_2019_westminster_parliamentary_constituencies) |> 
  summarise(white_tot = sum(white_tot))


census <- population |> 
  left_join(sixteenplus) |> 
  left_join(eighteenplus) |> 
  left_join(over65) |> 
  mutate(over65 = over65_tot / pop_tot) |> 
  left_join(education) |> 
  mutate(degree = degree_tot / eighteenplus_tot) |> 
  left_join(disability) |> 
  mutate(disability = disability_tot / pop_tot) |> 
  left_join(health) |> 
  mutate(notgoodhealth = notgoodhealth_tot / pop_tot) |> 
  left_join(white) |> 
  mutate(white = white_tot / pop_tot) |> 
  rename(con_code = post_2019_westminster_parliamentary_constituencies_code) |> 
  select(con_code, over65, degree, notgoodhealth, white, pop_tot)

```


### Unite into one data frame

```{r, echo=FALSE}
df <- votes24 |> 
  left_join(votes19proj, by="con_code") |> 
  left_join(votes17proj, by="con_code") |> 
  left_join(census, by="con_code") |> 
  mutate(thousand_perkm = (pop_tot/1000) / units::set_units(st_area(geometry), km^2)) |> 
  st_as_sf() |> 
  select(-pop_tot) |> 
  select(con_code, region_name, constituency_name, first_party24 ,second_party24, third_party24, everything(), -geometry) |> 
  select(everything(), geometry) |> 
  filter(constituency_name != "Chorley")

df$region_name <- factor(df$region_name)
df$density <- df$thousand_perkm |> as.numeric()

dfhex <- df |> 
  st_drop_geometry() |> 
  left_join(hex24, by="con_code") |> 
  st_as_sf()

```

## Stan code

```{stan, output.var = "compiled_model_icar_varysd"}

data {
  int<lower=1> N;  // total number of observations
  array[N] int Y;  // response variable
  int<lower=1> K;  // number of population-level effects
  matrix[N, K] X;  // population-level design matrix
  int<lower=1> Kc;  // number of population-level effects after centering
  // data for the CAR structure
  int<lower=1> Nloc;
  array[N] int<lower=1> Jloc;
  int<lower=0> Nedges;
  array[Nedges] int<lower=1> edges1;
  array[Nedges] int<lower=1> edges2;
  vector[N] offsets;
  int prior_only;  // should the likelihood be ignored?
}

transformed data {
  matrix[N, Kc] Xc;  // centered version of X without an intercept
  vector[Kc] means_X;  // column means of X before centering
  for (i in 2:K) {
    means_X[i - 1] = mean(X[, i]);
    Xc[, i - 1] = X[, i] - means_X[i - 1];
  }
}

parameters {
  vector[Kc] b;  // regression coefficients
  real Intercept;  // temporary intercept for centered predictors
  vector<lower=0> [Nloc] sdcar;  // SD of the CAR structure
  // parameters for the ICAR structure
  vector[N] zcar;
}

transformed parameters {
  // scaled parameters for the ICAR structure
  vector[N] rcar;
  real lprior = 0;  // prior contributions to the log posterior
  // compute scaled parameters for the ICAR structure
  for (n in 1:N) {
    rcar[n] = zcar[n] .* sdcar[Jloc[n]];
  }
  lprior += student_t_lpdf(sdcar | 3, 0, 2.5)
    - 1 * student_t_lccdf(0 | 3, 0, 2.5);
}

model {
  // =====================================================
  // PRIORS
  // =====================================================
  target += lprior;                    // prior on sdcar via student_t
  
  Intercept ~ normal(0, 10);             // prior on Intercept
  b ~ normal(0, 10);                     // prior on regression coefficients
  
  target += -0.5 * dot_self(zcar[edges1] - zcar[edges2]);  // ICAR prior on zcar
  target += normal_lpdf(sum(zcar) | 0, 0.001 * Nloc);      // soft sum-to-zero constraint on zcar
  
  // =====================================================
  // LIKELIHOOD
  // =====================================================
  if (!prior_only) {
    vector[N] mu = rep_vector(0.0, N);
    mu += Intercept + Xc * b + offsets;
    for (n in 1:N) {
      mu[n] += rcar[n];
    }
    target += poisson_log_lpmf(Y | mu);
  }
}

generated quantities {
  // actual population-level intercept
  real b_Intercept = Intercept - dot_product(means_X, b);
  
  // Log likelihood for observed data
  vector[N] log_lik;  // log likelihood for each observation
  for (n in 1:N) {
    log_lik[n] = poisson_log_lpmf(Y[n] | Intercept + Xc[n] * b + offsets[n] + rcar[n]);
  }
}

```


## LibDem model

```{r}
# matrix version of nb df for stan:
dfnbld <- st_bridges(df[df$ld24!=0,], "constituency_name", nb_structure = "matrix") |> 
  st_force_join_nb("Isle of Wight East","Gosport") |> 
  st_force_join_nb("Isle of Wight West","New Forest West") |> 
  mutate(first_party19 = factor(first_party19,
                                levels=c("ld","lab","con","other")),
         second_party19 = factor(second_party19,
                                levels=c("ld","lab","con","ruk","other")),
         third_party19 = factor(third_party19,
                                levels=c("ld","lab","con","ruk","other")),
         majority_prop = majority19/valid_votes19,
         majority_prop_scale = as.numeric(scale(majority19/valid_votes19)),
         degree_scale = as.numeric(scale(degree)),
         notgoodhealth_scale = as.numeric(scale(notgoodhealth)),
         white_scale = as.numeric(scale(white))) |> 
  mutate(second_party19comp = case_when(second_party19 == "ruk" ~ "other/ruk",
                                        second_party19 == "other" ~ "other/ruk",
                                        TRUE ~ second_party19),
         second_party19comp = factor(second_party19comp,
                                levels=c("ld","lab","con","other/ruk")))

W <- dfnbld$nb

modmat <- model.matrix(ld24 ~
                         first_party19 + second_party19comp * majority_prop_scale +
                         degree_scale + notgoodhealth_scale + white_scale, 
                       data=dfnbld)

X <- modmat

y <- dfnbld$ld24

E <- dfnbld$valid_votes24

data_prep <- prep_icar_data(dfnbld$nb)

datalist <- list(N = nrow(X),         # number of observations
                 K = ncol(X),         # number of coefficients
                 Kc = ncol(X)-1,
                 X = X,               # design matrix
                 Y = y,               # observed number of cases
                 offsets = log(E),    # log(expected) num. cases
                 W_n = sum(W) / 2,    # number of neighbour pairs
                 W = W,
                 Nloc = length(unique(dfnbld$region_name)),
                 Jloc = as.numeric(dfnbld$region_name),
                 Nedges = data_prep$n_edges,
                 edges1 = data_prep$node1,
                 edges2 = data_prep$node2,
                 prior_only = 0)

```


```{r}
# mod7_ld <- rstan::sampling(
#   compiled_model_icar_varysd,
#   data = datalist,
#   chains = 4,
#   warmup = 1000,
#   iter = 60000,
#   cores = 4,
#   refresh = 100,
#   verbose = FALSE,
#   thin = 10,
#   control = list(adapt_delta = 0.99,
#                  max_treedepth = 13),
#   seed = 12345,
# )

```


```{r}
# saveRDS(mod7_ld, here("mods24","mods_ld","mod7_ld.rds"))

# mod7_ld <- readRDS(here("mods24","mods_ld","mod7_ld.rds"))

```


```{r}
# To use bridge sampling with a saved rather than freshly-run model...

# Recreate a clean stanfit object of same dimensions with no sampling
dummy_fit <- sampling(
  compiled_model_icar_varysd,
  data = datalist,
  chains = 4,
  iter = 60000,
  warmup = 1000,
  algorithm = "Fixed_param",  # Prevent actual sampling
  refresh = 0
)
```

```{r}
# Inject real posterior draws into dummy object

mod7_ld <- readRDS(here("mods24","mods_ld","mod7_ld.rds"))

dummy_fit@sim <- mod7_ld@sim
dummy_fit@inits <- mod7_ld@inits
dummy_fit@mode <- mod7_ld@mode
dummy_fit@stanmodel <- compiled_model_icar_varysd  # Make sure compiled

```

```{r}
# Run bridge sampling
# rm(mod7_ld) # for space

margloglik_mod7_ld <- bridge_sampler(
  samples = dummy_fit,
  data = datalist,
  silent = TRUE
)

```


```{r}
# saveRDS(margloglik_mod7_ld, here("mods24","mods_ld","margloglik_mod7_ld.rds"))

margloglik_mod7_ld <- readRDS(here("mods24","mods_ld","margloglik_mod7_ld.rds"))

```

## Conservative model

```{r}

# matrix version of nb df for stan:
dfnbcon <- st_bridges(df[df$con24!=0,], "constituency_name", nb_structure = "matrix") |> 
  st_force_join_nb("Isle of Wight East","Gosport") |> 
  st_force_join_nb("Isle of Wight West","New Forest West") |> 
  mutate(first_party19 = factor(first_party19,
                                levels=c("con","lab","ld","other")),
         second_party19 = factor(second_party19,
                                levels=c("con","lab","ld","ruk","other")),
         third_party19 = factor(third_party19,
                                levels=c("con","lab","ld","ruk","other")),
         majority_prop = majority19/valid_votes19,
         majority_prop_scale = as.numeric(scale(majority19/valid_votes19)),
         degree_scale = as.numeric(scale(degree)),
         notgoodhealth_scale = as.numeric(scale(notgoodhealth)),
         white_scale = as.numeric(scale(white))) |> 
  mutate(second_party19comp = case_when(second_party19 == "ruk" ~ "other/ruk",
                                        second_party19 == "other" ~ "other/ruk",
                                        TRUE ~ second_party19),
         second_party19comp = factor(second_party19comp,
                                levels=c("con","lab","ld","other/ruk")))

W <- dfnbcon$nb

modmat <- model.matrix(con24 ~
                         first_party19 + second_party19comp * majority_prop_scale +
                         degree_scale + notgoodhealth_scale + white_scale, 
                       data=dfnbcon)

X <- modmat

y <- dfnbcon$con24

E <- dfnbcon$valid_votes24

data_prep <- prep_icar_data(dfnbcon$nb)

datalist <- list(N = nrow(X),         # number of observations
                 K = ncol(X),         # number of coefficients
                 Kc = ncol(X)-1,
                 X = X,               # design matrix
                 Y = y,               # observed number of cases
                 offsets = log(E), # log(expected) num. cases
                 W_n = sum(W) / 2,    # number of neighbour pairs
                 W = W,
                 Nloc = length(unique(dfnbcon$region_name)),
                 Jloc = as.numeric(dfnbcon$region_name),
                 Nedges = data_prep$n_edges,
                 edges1 = data_prep$node1,
                 edges2 = data_prep$node2,
                 prior_only = 0)

```

```{r}
# mod7_con <- rstan::sampling(
#   compiled_model_icar_varysd,
#   data = datalist,
#   chains = 4,
#   warmup = 1000,
#   iter = 60000,
#   cores = 4,
#   refresh = 100,
#   verbose = FALSE,
#   thin = 10,
#   control = list(adapt_delta = 0.99,
#                  max_treedepth = 12),
#   seed = 12345,
# )

```


```{r}
# saveRDS(mod7_con, here("mods24","mods_con","mod7_con.rds"))

# mod7_con <- readRDS(here("mods24","mods_con","mod7_con.rds"))

```


```{r}
# To use bridge sampling with a saved rather than freshly-run model...

# Recreate a clean stanfit object of same dimensions with no sampling
dummy_fit <- sampling(
  compiled_model_icar_varysd,
  data = datalist,
  chains = 4,
  iter = 60000,
  warmup = 1000,
  algorithm = "Fixed_param",  # Prevent actual sampling
  refresh = 0
)
```

```{r}
# Inject real posterior draws into dummy object

mod7_con <- readRDS(here("mods24","mods_con","mod7_con.rds"))

dummy_fit@sim <- mod7_con@sim
dummy_fit@inits <- mod7_con@inits
dummy_fit@mode <- mod7_con@mode
dummy_fit@stanmodel <- compiled_model_icar_varysd  # Make sure compiled

```

```{r}
# Run bridge sampling
# rm(mod7_con) # for space

margloglik_mod7_con <- bridge_sampler(
  samples = dummy_fit,
  data = datalist,
  silent = TRUE
)

```


```{r}
# saveRDS(margloglik_mod7_con, here("mods24","mods_con","margloglik_mod7_con.rds"))

margloglik_mod7_con <- readRDS(here("mods24","mods_con","margloglik_mod7_con"))

```

## Labour model

```{r}

# matrix version of nb df for stan:
dfnblab <- st_bridges(df[df$lab24!=0,], "constituency_name", nb_structure = "matrix") |> 
  st_force_join_nb("Isle of Wight East","Gosport") |> 
  st_force_join_nb("Isle of Wight West","New Forest West") |> 
  mutate(first_party19 = factor(first_party19,
                                levels=c("lab","con","ld","other")),
         second_party19 = factor(second_party19,
                                levels=c("lab","con","ld","ruk","other")),
         third_party19 = factor(third_party19,
                                levels=c("lab","con","ld","ruk","other")),
         majority_prop = majority19/valid_votes19,
         majority_prop_scale = as.numeric(scale(majority19/valid_votes19)),
         degree_scale = as.numeric(scale(degree)),
         notgoodhealth_scale = as.numeric(scale(notgoodhealth)),
         white_scale = as.numeric(scale(white))) |> 
  mutate(second_party19comp = case_when(second_party19 == "ruk" ~ "other/ruk",
                                        second_party19 == "other" ~ "other/ruk",
                                        TRUE ~ second_party19),
         second_party19comp = factor(second_party19comp,
                                levels=c("lab","con","ld","other/ruk")))

W <- dfnblab$nb

modmat <- model.matrix(lab24 ~
                         first_party19 + second_party19comp * majority_prop_scale +
                         degree_scale + notgoodhealth_scale + white_scale, 
                       data=dfnblab)

X <- modmat

y <- dfnblab$lab24

E <- dfnblab$valid_votes24

data_prep <- prep_icar_data(dfnblab$nb)

datalist <- list(N = nrow(X),         # number of observations
                 K = ncol(X),         # number of coefficients
                 Kc = ncol(X)-1,
                 X = X,               # design matrix
                 Y = y,               # observed number of cases
                 offsets = log(E), # log(expected) num. cases
                 W_n = sum(W) / 2,    # number of neighbour pairs
                 W = W,
                 Nloc = length(unique(dfnblab$region_name)),
                 Jloc = as.numeric(dfnblab$region_name),
                 Nedges = data_prep$n_edges,
                 edges1 = data_prep$node1,
                 edges2 = data_prep$node2,
                 prior_only = 0)

```

```{r}
mod7_lab <- rstan::sampling(
  compiled_model_icar_varysd,
  data = datalist,
  chains = 4,
  warmup = 1000,
  iter = 60000,
  cores = 4,
  refresh = 100,
  verbose = FALSE,
  thin = 10,
  control = list(adapt_delta = 0.99,
                 max_treedepth = 12),
  seed = 12345,
)

```


```{r}
# saveRDS(mod7_lab, here("mods24","mods_lab","mod7_lab.rds"))

# mod7_lab <- readRDS(here("mods24","mods_lab","mod7_lab.rds"))

```


```{r}
# To use bridge sampling with a saved rather than freshly-run model...

# Recreate a clean stanfit object of same dimensions with no sampling
dummy_fit <- sampling(
  compiled_model_icar_varysd,
  data = datalist,
  chains = 4,
  iter = 60000,
  warmup = 1000,
  algorithm = "Fixed_param",  # Prevent actual sampling
  refresh = 0
)
```

```{r}
# Inject real posterior draws into dummy object

mod7_lab <- readRDS(here("mods24","mods_lab","mod7_lab.rds"))

dummy_fit@sim <- mod7_lab@sim
dummy_fit@inits <- mod7_lab@inits
dummy_fit@mode <- mod7_lab@mode
dummy_fit@stanmodel <- compiled_model_icar_varysd  # Make sure compiled

```

```{r}
# Run bridge sampling
# rm(mod7_lab) # for space

margloglik_mod7_lab <- bridge_sampler(
  samples = dummy_fit,
  data = datalist,
  silent = TRUE
)

```


```{r}
# saveRDS(margloglik_mod7_lab, here("mods24","mods_lab","margloglik_mod7_lab.rds"))

margloglik_mod7_lab <- readRDS(here("margloglik","margloglik_mod7_lab"))

```

## Reform UK model

```{r}

# matrix version of nb df for stan:
dfnbruk <- st_bridges(df[df$ruk24!=0,], "constituency_name", nb_structure = "matrix") |> 
  st_force_join_nb("Isle of Wight East","Gosport") |> 
  st_force_join_nb("Isle of Wight West","New Forest West") |> 
  mutate(first_party19 = factor(first_party19,
                                levels=c("lab","con","ld","other")),
         second_party19 = factor(second_party19,
                                levels=c("ruk","lab","con","ld","other")),
         third_party19 = factor(third_party19,
                                levels=c("ruk","lab","con","ld","other")),
         majority_prop = majority19/valid_votes19,
         majority_prop_scale = as.numeric(scale(majority19/valid_votes19)),
         degree_scale = as.numeric(scale(degree)),
         notgoodhealth_scale = as.numeric(scale(notgoodhealth)),
         white_scale = as.numeric(scale(white))) |> 
  mutate(second_party19comp = case_when(second_party19 == "ruk" ~ "other/ruk",
                                        second_party19 == "other" ~ "other/ruk",
                                        TRUE ~ second_party19),
         second_party19comp = factor(second_party19comp,
                                levels=c("other/ruk","lab","con","ld")))

W <- dfnbruk$nb

modmat <- model.matrix(ruk24 ~
                         first_party19 + second_party19comp * majority_prop_scale +
                         degree_scale + notgoodhealth_scale + white_scale, 
                       data=dfnbruk)

X <- modmat

y <- dfnbruk$ruk24

E <- dfnbruk$valid_votes24

data_prep <- prep_icar_data(dfnbruk$nb)

datalist <- list(N = nrow(X),         # number of observations
                 K = ncol(X),         # number of coefficients
                 Kc = ncol(X)-1,
                 X = X,               # design matrix
                 Y = y,               # observed number of cases
                 offsets = log(E), # log(expected) num. cases
                 W_n = sum(W) / 2,    # number of neighbour pairs
                 W = W,
                 Nloc = length(unique(dfnbruk$region_name)),
                 Jloc = as.numeric(dfnbruk$region_name),
                 Nedges = data_prep$n_edges,
                 edges1 = data_prep$node1,
                 edges2 = data_prep$node2,
                 prior_only = 0)

```

```{r}
mod7_ruk <- rstan::sampling(
  compiled_model_icar_varysd,
  data = datalist,
  chains = 4,
  warmup = 1000,
  iter = 60000,
  cores = 4,
  refresh = 100,
  verbose = FALSE,
  thin = 10,
  control = list(adapt_delta = 0.99,
                 max_treedepth = 12),
  seed = 12345,
)

```


```{r}
# saveRDS(mod7_ruk, here("mods24","mods_ruk","mod7_ruk.rds"))

# mod7_ruk <- readRDS(here("mods24","mods_ruk","mod7_ruk.rds"))

```


```{r}
# To use bridge sampling with a saved rather than freshly-run model...

# Recreate a clean stanfit object of same dimensions with no sampling
dummy_fit <- sampling(
  compiled_model_icar_varysd,
  data = datalist,
  chains = 4,
  iter = 60000,
  warmup = 1000,
  algorithm = "Fixed_param",  # Prevent actual sampling
  refresh = 0
)
```

```{r}
# Inject real posterior draws into dummy object

mod7_ruk <- readRDS(here("mods24","mods_ruk","mod7_ruk.rds"))

dummy_fit@sim <- mod7_ruk@sim
dummy_fit@inits <- mod7_ruk@inits
dummy_fit@mode <- mod7_ruk@mode
dummy_fit@stanmodel <- compiled_model_icar_varysd  # Make sure compiled

```

```{r}
# Run bridge sampling
# rm(mod7_ruk) # for space

margloglik_mod7_ruk <- bridge_sampler(
  samples = dummy_fit,
  data = datalist,
  silent = TRUE
)

```



```{r}
# saveRDS(margloglik_mod7_ruk, here("mods24","mods_ruk","margloglik_mod7_ruk.rds"))

margloglik_mod7_ruk <- readRDS(here("mods24","mods_ruk","margloglik_mod7_ruk"))

```

## Checks

### Convergence: R-hat and ESS

```{r}
sumdf_mod7_ld <- summary(mod7_ld, probs = c(0.025, 0.5, 0.975))$summary |> 
  data.frame()
```

### Divergent transitions and treedepth warnings

```{r}
# count divergent transitions
sum(sapply(rstan::get_sampler_params(mod7_ld, inc_warmup = FALSE), function(x) sum(x[, "divergent__"])))
```

```{r}
# count transitions hitting max treedepth
sum(sapply(rstan::get_sampler_params(mod7_ld, FALSE), function(x) sum(x[, "treedepth__"] == 13)))  # Adjust if max_treedepth ≠ 12

```

```{r}
# percentage transitions hitting max treedepth

# Get all sampler params
sampler_params <- rstan::get_sampler_params(mod7_ld, inc_warmup = FALSE)

# Count total post-warmup iterations
total_iterations <- sum(sapply(sampler_params, nrow))

# Count how many hit the max treedepth (assumed to be 12; adjust if needed)
treedepth_hits <- sum(sapply(sampler_params, function(x) sum(x[, "treedepth__"] == 13)))

# Calculate percentage
treedepth_percent <- 100 * treedepth_hits / total_iterations

# Display
treedepth_percent

```

### Examine these max treedepth parameters more carefully

```{r}
# which parameters are hitting max treedepth

compare_max_treedepth_draws <- function(stanfit_obj, max_td = 12) {
  # Get sampler parameters
  sampler_params <- rstan::get_sampler_params(stanfit_obj, inc_warmup = FALSE)
  n_iter <- nrow(sampler_params[[1]])
  n_chains <- length(sampler_params)
  
  # Get indices of iterations that hit max treedepth
  max_td_indices <- lapply(sampler_params, function(x) which(x[, "treedepth__"] == max_td))
  
  # Reconstruct flat indices across chains
  draw_indices <- unlist(lapply(1:n_chains, function(chain) {
    ((chain - 1) * n_iter + 1):(chain * n_iter)
  }))
  
  max_td_draws_idx <- unlist(lapply(1:n_chains, function(chain) {
    draw_indices[((chain - 1) * n_iter) + max_td_indices[[chain]]]
  }))
  
  # Extract full posterior draws
  posterior_draws <- as.data.frame(stanfit_obj)
  
  # Subset: max treedepth vs regular draws
  td_draws <- posterior_draws[max_td_draws_idx, ]
  rest_draws <- posterior_draws[-max_td_draws_idx, ]
  
  # Compare means and sds
  compare_stats <- function(param) {
    mean_td <- mean(td_draws[[param]], na.rm = TRUE)
    mean_rest <- mean(rest_draws[[param]], na.rm = TRUE)
    sd_td <- sd(td_draws[[param]], na.rm = TRUE)
    sd_rest <- sd(rest_draws[[param]], na.rm = TRUE)
    
    data.frame(
      parameter = param,
      mean_diff = mean_td - mean_rest,
      sd_ratio = sd_td / sd_rest
    )
  }
  
  param_names <- colnames(posterior_draws)
  results <- do.call(rbind, lapply(param_names, compare_stats))
  
  results <- results[order(-abs(results$mean_diff)), ]
  return(results)
}

# This will give a sorted table of parameters showing:
# mean_diff: how much the parameter's mean differs when treedepth was maxed
# sd_ratio: how much more variable it was compared to the rest
compare_max_treedepth_draws(mod7_ruk)

```

```{r}
# visualize the posterior distributions of parameters for iterations that hit the maximum treedepth versus those that did not, using ggplot2. 
# This helps identify whether those max treedepth transitions are occurring in tricky areas of parameter space

plot_max_treedepth_comparison <- function(stanfit_obj, param_names = NULL, max_td = 12, n_show = 5) {
  sampler_params <- rstan::get_sampler_params(stanfit_obj, inc_warmup = FALSE)
  n_iter <- nrow(sampler_params[[1]])
  n_chains <- length(sampler_params)

  # Get indices of max treedepth draws
  max_td_indices <- lapply(sampler_params, function(x) which(x[, "treedepth__"] == max_td))
  draw_indices <- unlist(lapply(1:n_chains, function(chain) {
    ((chain - 1) * n_iter + 1):(chain * n_iter)
  }))
  max_td_draws_idx <- unlist(lapply(1:n_chains, function(chain) {
    draw_indices[((chain - 1) * n_iter) + max_td_indices[[chain]]]
  }))
  
  posterior_draws <- as.data.frame(stanfit_obj)
  td_draws <- posterior_draws[max_td_draws_idx, ]
  rest_draws <- posterior_draws[-max_td_draws_idx, ]
  
  if (is.null(param_names)) {
    # Automatically select most affected parameters
    diffs <- compare_max_treedepth_draws(stanfit_obj, max_td)
    param_names <- head(diffs$parameter, n_show)
  }

  # Prepare long data for ggplot
  td_long <- td_draws[, param_names, drop = FALSE]
  td_long$type <- "max_treedepth"
  
  rest_long <- rest_draws[, param_names, drop = FALSE]
  rest_long$type <- "other"
  
  df_long <- rbind(
    reshape2::melt(td_long, id.vars = "type"),
    reshape2::melt(rest_long, id.vars = "type")
  )

  # Plot
  ggplot(df_long, aes(x = value, fill = type)) +
    geom_density(alpha = 0.5) +
    facet_wrap(~variable, scales = "free", ncol = 2) +
    theme_minimal() +
    labs(
      title = "Comparison of Posterior Draws",
      subtitle = "Max treedepth vs. other iterations",
      x = "Parameter value",
      y = "Density"
    ) +
    scale_fill_manual(values = c("max_treedepth" = "#D55E00", "other" = "#0072B2"))
}

```

```{r}
# example
plot_max_treedepth_comparison(mod7_ruk)

# This will show density plots for the 5 most affected parameters. You can override param_names = c("b[1]", "b[2]", ...) to plot specific ones.
```

```{r}

# This will give you the top 10 parameters with the biggest mean differences between samples with and without max treedepth, helping you spot which parameters may be causing issues.

compare_max_treedepth_draws <- function(stanfit_obj, max_td = 12, n_show = 10) {
  sampler_params <- rstan::get_sampler_params(stanfit_obj, inc_warmup = FALSE)
  n_iter <- nrow(sampler_params[[1]])
  n_chains <- length(sampler_params)
  
  draw_indices <- unlist(lapply(1:n_chains, function(chain) {
    ((chain - 1) * n_iter + 1):(chain * n_iter)
  }))
  
  max_td_indices <- unlist(lapply(1:n_chains, function(chain) {
    sampler_chain <- sampler_params[[chain]]
    draw_indices[((chain - 1) * n_iter) + which(sampler_chain[, "treedepth__"] == max_td)]
  }))

  posterior_draws <- as.data.frame(stanfit_obj)

  # Separate the draws
  td_draws <- posterior_draws[max_td_indices, , drop = FALSE]
  rest_draws <- posterior_draws[-max_td_indices, , drop = FALSE]

  # Compare means across all parameters
  mean_diff <- abs(colMeans(td_draws) - colMeans(rest_draws))
  result <- sort(mean_diff, decreasing = TRUE)
  
  data.frame(parameter = names(result)[1:n_show], mean_diff = result[1:n_show])
}

```

### Check energy diagnostic (for E-BFMI)

```{r}
rstan::check_energy(mod7_ruk)

```

### Visual diagnostics using `bayesplot`

```{r}
library(bayesplot)
posterior <- rstan::extract(mod7_ruk)

# Trace plots
mcmc_trace(as.array(mod7_ruk), pars = c("Intercept", "b[1]", "b[2]"))

# Pair plots (to detect funnel-like structures or strong correlations)
mcmc_pairs(as.array(mod7_ruk), pars = c("Intercept", "b[1]", "b[2]"))

```

### Use `shinystan` for an interactive diagnostic tool

```{r}
# gives full diagnostic interface with convergence, divergences, treedepth, autocorrelation, and more.
library(shinystan)
launch_shinystan(mod7_ruk)

```


